model:
  net:
    class_path: modules.baseline_fuxi.FuXi
    init_args:
      # Input infos
      input_size: 320
      patch_size: 5
      in_channel: 69
      hidden_dim: 1024
      swin_depth: 46

      # Tricks
      add_grad_loss: False
      margin: 30
      # Tasks
      loss_type: 'mse'
      use_weights: False
      # all 69 variables
      masked_picked_idx: [0, 1, 2, 3, 
                          4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 
                          17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,
                          30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42,
                          43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,
                          56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68
                          ]
      log_picked_idx: [0, 1, 2, 3, 
                      4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 
                      17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 
                      30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 
                      43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 
                      56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68]

  restart_path: ""
  opt_name: adamw
  # opt_name: rmsprop
  rmsprop_alpha: 0.99 # for rmsprop optimizer
  lr: 3e-5
  beta_1: 0.9 # for adam optimizer
  beta_2: 0.999 # for adam optimizer
  weight_decay: 0.02
  warmup_steps: 3000
  warmup_start_lr: 0
  eta_min: 1e-7
  # dataset configs
  datasets: ['hrrr']
  not_used_levels: []
  norm_path: './'
  data_type: 32
  max_steps: 50000
  need_rescale_grad: False
